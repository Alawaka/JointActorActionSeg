
# coding: utf-8

import sys
sys.path.append('..')
import utils.matterport_utils as matterport_utils
from models.model_misc import compose_image_meta
from utils.flow import read_flo_file
from dataIO.a2d_dataset import A2DDataset
from cfg.config import Config

import os.path as osp
import os
import numpy as np
import random
import skimage
import pickle
import h5py


def preprocess_image(dataset, video_id, frame_id, config, use_mini_mask=True):
    """Load and return ground truth data for an image (image, mask, bounding boxes).

    use_mini_mask: If False, returns full-size masks that are the same height
        and width as the original image. These can be big, for example
        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,
        224x224 and are generated by extracting the bounding box of the
        object and resizing it to MINI_MASK_SHAPE.

    Returns: A dict of
    image: [height, width, 3]
    image_meta: meta info of image
    image_path: path of image
    bbox: [instance_count, (y1, x1, y2, x2, actor_class_id, action_class_id)]
    mask: [height, width, instance_count]. The height and width are those
        of the image unless use_mini_mask is True, in which case they are
        defined in MINI_MASK_SHAPE.
    """
    image_path = osp.join(dataset.image_dir, video_id, '%05d.png' % frame_id)
    flow_path = osp.join(dataset.flow_dir, video_id, '%05d.flo' % frame_id)
    anno_path = osp.join(dataset.anno_dir, video_id, '%05d.mat' % frame_id)
    has_anno = osp.exists(anno_path)
    # Load image and mask
    image = load_image(image_path)
    flow = load_flow(flow_path)
    shape = image.shape
    image, window, scale, padding = matterport_utils.resize_image(
        image, 
        min_dim=config.IMAGE_MIN_DIM, 
        max_dim=config.IMAGE_MAX_DIM,
        padding=config.IMAGE_PADDING)
    flow = matterport_utils.resize_image(
        flow,
        min_dim=config.IMAGE_MIN_DIM,
        max_dim=config.IMAGE_MAX_DIM,
        padding=config.IMAGE_PADDING,
        mode='flow')[0]
    # Active classes
    # Different datasets have different classes, so track the
    # classes supported in the dataset of this image.
    active_actor_class_ids = np.ones([dataset.num_actor_classes], dtype=np.int32)
    active_action_class_ids = np.ones([dataset.num_action_classes], dtype=np.int32)
    # Image meta data. Here image_id is set -1, to be consistent with args in
    # compose_image_meta, while distinct.
    image_meta = compose_image_meta(-1, shape, window, active_actor_class_ids, active_action_class_ids)
    
    if not has_anno:
        rtn_value = {
            'image': image,
            'flow': flow,
            'image_path': image_path,
            'image_meta': image_meta,
        }
        return rtn_value
    
    mask, actor_class_ids, action_class_ids = load_mask(dataset, anno_path)
    mask = matterport_utils.resize_mask(mask, scale, padding)
    # Bounding boxes. Note that some boxes might be all zeros
    # if the corresponding mask got cropped out.
    # bbox: [num_instances, (y1, x1, y2, x2)]
    bbox = matterport_utils.extract_bboxes(mask)
    # Add class_id as the last value in bbox
    bbox = np.hstack([bbox, actor_class_ids[:, np.newaxis], action_class_ids[:, np.newaxis]])
    # Resize masks to smaller size to reduce memory usage
    if use_mini_mask:
        mask = matterport_utils.minimize_mask(bbox, mask, config.MINI_MASK_SHAPE)

    rtn_value = {
        'image': image,
        'flow': flow,
        'image_path': image_path,
        'image_meta': image_meta,
        'mask': mask,
        'bbox': bbox,
    }
    return rtn_value


def load_image(image_path):
    """Load the specified image and return a [H,W,3] Numpy array.
    """
    # Load image
    image = skimage.io.imread(image_path)
    # If grayscale. Convert to RGB for consistency.
    if image.ndim != 3:
        image = skimage.color.gray2rgb(image)
    return image


# Deprecated. Kept here for reference. This will load semantic masks, rather than instance masks.
def load_mask_old(dataset, anno_path):
    anno = skimage.io.imread(anno_path).astype(np.int64)
    anno = anno[:,:,0]*10**6 + anno[:,:,1]*10**3 + anno[:,:,2]
    color_codes = np.unique(anno).tolist()[1:] # exclude 0 for background
    num_instances = len(np.unique(anno)) - 1
    assert num_instances == len(color_codes) # TODO: if assert passes, change to num_instances = len(color_codes)

    mask = np.empty([anno.shape[0], anno.shape[1], num_instances])
    for i in range(num_instances):
        mask[:,:,i] = anno == color_codes[i]
    actor_class_ids = np.array(list(map(lambda x: dataset.color_to_actor_class_name[x], color_codes)))
    action_class_ids = np.array(list(map(lambda x: dataset.color_to_action_class_name[x], color_codes)))
    return mask, actor_class_ids, action_class_ids


def load_mask(dataset, anno_path):
    ''' Load instance masks and corresponding actor and action class ids.
        instance ids are larger or equal to 1, while 0 is saved for background
        in both actor and action classes.
    '''
    with h5py.File(anno_path, mode='r') as f:
        ids = np.array(f['id'])[0].astype(np.int64) # (num_instances, )
        actor_class_ids = ids // 10 # tens digit of ids
        action_class_ids = ids - actor_class_ids * 10 # units digit of ids
        mask = np.transpose(np.array(f['reMask'])).astype(np.float64)
        if len(mask.shape) < 3:
            mask = np.expand_dims(mask, -1)
    return mask, actor_class_ids, action_class_ids


def load_flow(flow_path):
    return read_flo_file(flow_path)

if __name__ == '__main__':

    dataset = A2DDataset(split='train', dataset_dir='/vision/u/jingweij/Datasets/A2D/Release/')
    dataset.prepare()

    class A2DConfig(Config):
        """Configuration for training on the toy shapes dataset.
        Derives from the base Config class and overrides values specific
        to the toy shapes dataset.
        """
        # Give the configuration a recognizable name
        NAME = "a2d"

        # Number of classes (including background)
        NUM_ACTOR_CLASSES = 1 + 7  # background + 7 actors
        NUM_ACTION_CLASSES = 1 + 9  # background + 9 actions

        # Use small images for faster training. Set the limits of the small side
        # the large side, and that determines the image shape.
        IMAGE_MIN_DIM = 256
        IMAGE_MAX_DIM = 256

    config = A2DConfig()
    config.display()

    all_video_ids = sorted(os.listdir(dataset.image_dir))

    video_id = np.random.choice(all_video_ids)
    frame_id = np.random.choice(len(os.listdir(osp.join(dataset.image_dir, video_id)))) + 1

    for i in range(100):
        video_id = np.random.choice(all_video_ids)
        frame_id = np.random.choice(len(os.listdir(osp.join(dataset.image_dir, video_id)))) + 1
        dic = preprocess_image(dataset, video_id, frame_id, config, use_mini_mask=True)
        with open('../tmp/%03d.pkl' % i, 'wb') as f:
            pickle.dump(dic, f)

    li = []
    for j in range(2):
        for i in range(100):
            with open('../tmp/%03d.pkl' % i, 'rb') as f:
                li.append(pickle.load(f))

